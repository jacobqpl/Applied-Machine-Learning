{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWTe9VS3_b11"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Week 3:  Regularization, Logistic Regression, and Evaluation (Due 09/28 11:59pm)\n",
    "\n",
    "For this assignment, you will be exercising on questions related to linear regression, polynomial feature expansion, underfitting/overfitting, and cross-validation.\n",
    "\n",
    "Each question is worth 20 points, for a total of 100 points. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "Submit your completed notebook file to the Canvas site - IMPORTANT: please name your submitted file si670-hw1-youruniqname.ipynb and be sure to put your name at the top of your notebook file. Please also make sure to upload the html version.\n",
    "\n",
    "As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates: if you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put your name here:\n",
    "\n",
    "### Put your uniquename here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-_pUE4abw2eQ"
   },
   "source": [
    "### Preliminary\n",
    "In this assignment you will train several linear classifier models and evaluate how effectively they predict instances of fraud using data based on the Kaggle dataset (uploaded on Canvas). Then you'll perform a grid search to find optimal parameters. \n",
    " \n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run this cell if you are using Colab\n",
    "\n",
    "# !rm -rf fraud_data.csv\n",
    "\n",
    "# import io\n",
    "\n",
    "# from google.colab import files as colab_files\n",
    "# uploaded = colab_files.upload()\n",
    "# files = {'fraud_data.csv': io.BytesIO(uploaded['fraud_data.csv'])}\n",
    "\n",
    "# # upload 'fraud_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are using Jupyter\n",
    "files = {'fraud_data.csv': 'fraud_data.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(files['fraud_data.csv'])\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itE2L8t4w2ee"
   },
   "source": [
    "### Question 1 (20 points)\n",
    "\n",
    "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
    "\n",
    "Then train a LogisticRegression classifier with C=1. What is the accuracy? What is the recall?\n",
    "\n",
    "*This function should a return a tuple with four floats, i.e. `(dummy_accuracy, dummy_recall, lr_accuracy, lr_recall)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176563</td>\n",
       "      <td>0.323798</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>1.047002</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>-0.728586</td>\n",
       "      <td>0.084678</td>\n",
       "      <td>-0.069246</td>\n",
       "      <td>-0.266389</td>\n",
       "      <td>0.155315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>-0.341365</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>0.415211</td>\n",
       "      <td>-0.581949</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.681109</td>\n",
       "      <td>-3.934776</td>\n",
       "      <td>-3.801827</td>\n",
       "      <td>-1.147468</td>\n",
       "      <td>-0.735540</td>\n",
       "      <td>-0.501097</td>\n",
       "      <td>1.038865</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>-2.274423</td>\n",
       "      <td>1.527782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652202</td>\n",
       "      <td>0.272684</td>\n",
       "      <td>-0.982151</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.195321</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>0.056501</td>\n",
       "      <td>912.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.140729</td>\n",
       "      <td>0.453484</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>2.383132</td>\n",
       "      <td>0.343287</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.173310</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.107073</td>\n",
       "      <td>-3.298902</td>\n",
       "      <td>-0.184092</td>\n",
       "      <td>-1.795744</td>\n",
       "      <td>2.137564</td>\n",
       "      <td>-1.684992</td>\n",
       "      <td>-2.015606</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.869659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.927656</td>\n",
       "      <td>-0.049560</td>\n",
       "      <td>-1.892866</td>\n",
       "      <td>-0.575431</td>\n",
       "      <td>0.266573</td>\n",
       "      <td>0.414184</td>\n",
       "      <td>62.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.314818</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>-0.124577</td>\n",
       "      <td>-0.627638</td>\n",
       "      <td>2.651762</td>\n",
       "      <td>3.428128</td>\n",
       "      <td>0.194637</td>\n",
       "      <td>0.670674</td>\n",
       "      <td>-0.442658</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312774</td>\n",
       "      <td>-0.799494</td>\n",
       "      <td>-0.064488</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>-0.429550</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>-0.015051</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
       "1  0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
       "2  1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
       "3 -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
       "4 -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0 -0.069246 -0.266389  0.155315  ... -0.109627 -0.341365  0.057845  0.499180   \n",
       "1 -0.626979 -2.274423  1.527782  ...  0.652202  0.272684 -0.982151  0.165900   \n",
       "2  0.173310 -0.808999  0.775436  ... -0.003802  0.058556 -0.121177 -0.304215   \n",
       "3 -0.007181 -0.165760  0.869659  ...  0.130648  0.329445  0.927656 -0.049560   \n",
       "4  0.670674 -0.442658  0.133499  ... -0.312774 -0.799494 -0.064488  0.953062   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.415211 -0.581949  0.015472  0.018065    4.67      0  \n",
       "1  0.360251  0.195321 -0.256273  0.056501  912.00      0  \n",
       "2  0.645893  0.122600 -0.012115 -0.005945    1.00      0  \n",
       "3 -1.892866 -0.575431  0.266573  0.414184   62.10      0  \n",
       "4 -0.429550  0.158225  0.076943 -0.015051    2.67      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return dummy_accuracy, dummy_recall, lr_accuracy, lr_recall\n",
    "\n",
    "# answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (20 points)\n",
    "\n",
    "Fit the LogisticRegression with `C` varying from `[[0.1, 1, 10]` and report the accuracy, precision, recall, and F1 scores for each choice of `C`.\n",
    "\n",
    "*This function should a return a tuple with four lists, i.e. `(accuracy_list, precision_list, recall_list, f1_list)`, and each list should contain 3 numbers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_list\n",
    "\n",
    "# answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (20 points)\n",
    "\n",
    "Train a logistic regression classifier with `C=10` using X_train and y_train.\n",
    "\n",
    "For the logistic regression classifier, create (1) a precision-recall curve and (2) a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
    "\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
    "\n",
    "Looking at the ROC curve, what is the true positive rate when the false positive rate is `0.16`?\n",
    "\n",
    "*This function should return a tuple with two floats, i.e. `(recall_at_p75, tpr_at_fpr16)`.*\n",
    "*You should also includce code to generate the precision/recall and ROC curves above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return recall_at_p75, tpr_at_fpr16\n",
    "\n",
    "# answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (20 Points)\n",
    "\n",
    "Suppose you have trained a classifier distinguishing Benign vs Malignant cancers. And the confusion matrix of your classifier is given below.\n",
    "\n",
    "|      \t| Predicted: Benign \t| Predicted: Malignant \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| Actual: Benign \t|    10000\t|   100 \t|\n",
    "| Actual: Malignant  \t|    200\t|   10 \t|\n",
    "\n",
    "### Question (a) (10 points) \n",
    "If we assume Benign is the positive class and Malignant is the negative class, what are the precision and recall for Benign? If we assume Malignant is the positive class and Benign is the negative class, what are the precision and recall for Malignant?\n",
    "\n",
    "*This function should return a tuple of four float numbers: `(precision_benign, recall_genign, precision_maligant, recall_maligant)`. You can calculate these scores either by coding or by hands.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_four_a():\n",
    "    \n",
    "    # Coding or manually calculating the precision and recall scores here. \n",
    "\n",
    "    return precision_benign, recall_genign, precision_maligant, recall_maligant\n",
    "\n",
    "# answer_four_a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (b) (10 points) \n",
    "If you have another classifier with the following confusion matrix, which classifier do you prefer and why? (Hint: calculate the precision and recall scores for this classifier and compare with the previous classifier.)\n",
    "\n",
    "|      \t| Predicted: Benign \t| Predicted: Malignant \t|\n",
    "|:----:\t|----\t|----\t|\n",
    "| Actual: Benign \t|    7000\t|   3100 \t|\n",
    "| Actual: Malignant  \t|    30\t|   180 \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to quesiton 4 (b)\n",
    "\n",
    "Write your answer here.\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgXuLM17VoZ-"
   },
   "source": [
    "## Question 5 (20 Points)\n",
    "\n",
    "Now, we will compare the performance of Ridge, Lasso and OLS perform on the dataset where the relationship between X and y is non-linear.\n",
    "\n",
    "Let's start by generating some data using the function below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_data(n_samples, n_features, noise=0.0, random_state=670):\n",
    "    assert n_features > 1\n",
    "    rs = np.random.RandomState(random_state)\n",
    "    X = rs.uniform(size=(n_samples, n_features))\n",
    "    y = 3 * np.sin(2*np.pi * X[:, 0]) + 6.7 * X[:, 1] + 10 * np.power(X[:, 2], 3) + noise * rs.normal(size=(n_samples,))\n",
    "    return X, y\n",
    "X, y = generate_data(n_samples = 200, n_features=10, noise=1, random_state=670)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (a) Feature expansion (5 points)\n",
    "First, we are going use sklearn.preprocessing.PolynomialFeatures with `degree = 3`  to expand the feature (Remeber we did that in Lab 2!) \n",
    "\n",
    "*This function should return `X_poly`, which is the new feature set after feature expansion.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def answer_five_expansion():\n",
    "    # Your code here\n",
    "    \n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (b) Split and Standardize (5 points)\n",
    "Then, split the training and testing data with `train_size = 0.8` and `random_state = 670`, and use the `sklearn.preprocessing.StandardScaler` to normalize the feature `X_poly` and . \n",
    "\n",
    "*This function should return the standardized dataset, `standardized_X_poly_train, standardized_X_poly_test, y_poly_train, y_poly_test`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def answer_five_split_standardize():\n",
    "    X_poly = answer_five_expansion()\n",
    "    \n",
    "    # Your code\n",
    "    \n",
    "    \n",
    "    \n",
    "    return standardized_X_poly_train, standardized_X_poly_test, y_poly_train, y_poly_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (c-1) Model comparison (2 points)\n",
    "If we train different linear models, i.e., Linear Regression, Ridge, and Lasso, with the pre-processed training set (standardized_X_poly_train, y_poly_train), which model do you expect to generate the best performance on the testing set and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to Question 5 (c-1)\n",
    "Write your answer here.\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<br/><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (c-2) Model comparison and model selection (8 points)\n",
    "Next, let's see which model indeed performs better on our dataset. In this function, you will:\n",
    "* Train a Linear Regression model (with default settings), and print the training and testing R-squared scores;\n",
    "* Train a Ridge model for each alpha in the `alpha_list`, select the Ridge model that generates the highest R-squared score on the training set, print both the training and testing R-squared scores of the best-performing Ridge model (i.e., the model with the alpha that generates the highest R-squared score);\n",
    "* Train a Lasso model for each alpha in the `alpha_list`, select the Lasso model that generates the highest R-squared score on the training set, print both the training and testing R-squared scores of the best-performing Lasso model (i.e., the Lasso model with the alpha that generates the highest R-squared score);\n",
    "* Return the the training and testing R-squared scores of the Linear Regression model, the best-performing Ridge model, and the best-performing Lasso model: `linreg_r_2_train, linreg_r_2_test, best_ridgereg_r_2_train, best_ridgereg_r_2_test, best_lassoreg_r_2_train, best_lassoreg_r_2_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "\n",
    "def answer_five_compare():\n",
    "    \n",
    "    standardized_X_poly_train, standardized_X_poly_test, y_poly_train, y_poly_test = answer_five_split_standardize()\n",
    "    \n",
    "    alpha_list = [0.01, 0.1, 1, 2, 3, 5, 10, 50, 100, 200]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------- Linear Regression ----------------\n",
    "    # Your code\n",
    "    print('R-squared score of Linear Regression (train): {:.3f}'.format(linreg_r_2_train))    \n",
    "    print('R-squared score of Linear Regression (test): {:.3f}'.format(linreg_r_2_test))      \n",
    "    \n",
    "    \n",
    "    # -------------------- Ridge ---------------------------\n",
    "     \n",
    "    # Your code\n",
    "    \n",
    "    print('R-squared score of Ridge Regression (train): {:.3f}'.format(best_ridgereg_r_2_train))\n",
    "    print('R-squared score of Ridge Regression (test): {:.3f}'.format(best_ridgereg_r_2_test))\n",
    "        \n",
    "    # -------------------- Lasso ---------------------------\n",
    "    \n",
    "    # Your code\n",
    "          \n",
    "    print('R-squared score of Lasso Regression (train): {:.3f}'.format(best_lassoreg_r_2_train))\n",
    "    print('R-squared score of Lasso Regression (test): {:.3f}'.format(best_lassoreg_r_2_test))\n",
    "    \n",
    "    \n",
    "    return (linreg_r_2_train, linreg_r_2_test, best_ridgereg_r_2_train, best_ridgereg_r_2_test, \n",
    "            best_lassoreg_r_2_train, best_lassoreg_r_2_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "si670f19_lab_2_ans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
