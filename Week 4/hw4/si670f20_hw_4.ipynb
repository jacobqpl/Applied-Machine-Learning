{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWTe9VS3_b11"
   },
   "source": [
    "## SI 670 Applied Machine Learning, Week 4:  SVM, Data Leakage. (Due 10/5 11:59pm)\n",
    "\n",
    "For this assignment, question 1 is worth 50 points, and question 2 and 3 are worth 20 points each, for a total of 90 points. Correct answers and code receive full credit, but partial credit will be awarded if you have the right idea even if your final answers aren't quite right.\n",
    "\n",
    "Submit your completed notebook file AND corresponding **HTML** file to the Canvas site.\n",
    "\n",
    "As a reminder, the notebook code you submit must be your own work. Feel free to discuss general approaches to the homework with classmates: if you end up forming more of a team discussion on multiple questions, please include the names of the people you worked with at the top of your notebook file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrFh1l2Rms2-"
   },
   "source": [
    "### Question 1 (50 points)\n",
    "\n",
    "Please write the answers as well as your derivation process of the following questions. You can use either LaTeX or python code to represent your answer. For example, if you want to present <$x_1^2$>, in the LaTeX format you should write <(dollar sign) x_1^2 (dollar sign)>; in the python code format you should write <\\`x_1\\*\\*2\\`>. See [here](https://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/) for how to represent more mathmatical symbols in LaTeX format.\n",
    "\n",
    "*Note: The whole question 1 does not require coding.*\n",
    "\n",
    "#### (a) (10 points) \n",
    "The main metric we have been used to measure the quality of regression models is $R^2$, which is defined as, for n data points, $R^2 = 1 -  \\frac{\\sum_{i=1}^n(\\hat{y}_i - y_i)^2}{\\sum_{i=1}^n(y_i - \\bar{y})^2}$, where $y_i, \\hat{y}_i$ are the label and prediction of data point i, and $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$. We denote $\\frac{1}{n}\\sum_{i=1}^n(\\hat{y}_i - y_i)^2$ as *Unexplained Variation* and $\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2$ as *Total Variation*. \n",
    "\n",
    "Given 5 data points with labels (1, 3, 2, -3, 5, 2) and two classifiers A and B, the predictions of A is (1.1, 1.4, 1.3, -2, 2, 1.1) and the predictions of B is (1.7, 1.3, 0.3, -1, 1.5, 0.3). Please calculate and report the *Unexplained Variation*, *Total Variation*, and *$R^2$* for classifier A and B respectively. \n",
    "\n",
    "#### (b) (20 points) \n",
    "You are given 3 data points with two features and one labels as follows,\n",
    "\n",
    "|    X1\t| X2 \t| Y \t|\n",
    "|----\t|----\t|----\t|\n",
    "|   1\t|   1 \t| 1.05 \t|\n",
    "|   0.7 |  3 \t| 0.81 \t|\n",
    "|   2   |  0.5 \t| 2.045 |\n",
    "\n",
    "Suppose you have a linear regression model: $y = w_1 x_1 + w_2 x_2$, please calculate and report the least square error, the L1 regularization, and the L2 regularization terms when\n",
    "\n",
    "(i) $w_1 = 1, w_2 = 0$\n",
    "\n",
    "(ii) $w_1 = 1, w_2 = 0.02$\n",
    "\n",
    "If you set the regularization coefficient $C=1$, which of the above two weights is preferred by the Lasso and which is preferred by Ridge regression? Could you use this example to explain why Lasso prefers sparse models?\n",
    "\n",
    "#### (c) (20 points) \n",
    "One way to create a nonlinear method for regression or classifier is to first transform the feature vector via nonlinear feature map $\\Phi: R^d -> R^m$.\n",
    "\n",
    "* In regression, the nonlinear regression function is: $f(x) = w^T \\Phi(x) + b$ where $w \\in R^m, b\\in R$.\n",
    "\n",
    "* Inbinary classification, the nonlinear decision function is: $f(x) = w^T \\Phi(x) + b$ where $w \\in R^m, b \\in R$.\n",
    "\n",
    "Please answer the below question:\n",
    "\n",
    "(i) Let's first consider the case of scalar input in regression. Assuming we have a nonlinear regression function: $f(x) = a + bx + cx^2 + dx^3 = w^T \\Phi(x) + a$ where $x \\in R^1$, please answer what's the corresponding $w$, $\\Phi(x)$ and $m$ to map the $\\Phi: R^1 -> R^m$.\n",
    "\n",
    "(ii) Now, let's consider the case of binary classification in 2-dim space. Assuming we have a circular classifier to separate the training data (shown in below graph), i.e., $x -> sign{(x^{(1)} - c^{(1)})^2 + (x^{(2)} - c^{(2)})^2} - r^2$ for a certain center $c = [c^{(1)}, c^{(2)}]^T$ and radius r, where $x = [x^{(1)}, x^{(2)}]^T \\in R^2$. Consider $\\Phi(x) = [(x^{(1)})^2, (x^{(2)})^2, x^{(1)}, x^{(2)}]^T$, what's the corresponding $w$ and $b$ for the linear classifier in the transformed space. \n",
    "\n",
    "<img src=\"si670f20_assn4_q1c.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tj2J2AWWms3B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utw8lsT_ms3N"
   },
   "source": [
    "#### Answer 1(a)\n",
    "\n",
    "Write your answer to 1(a) here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_8loNK-ms3P"
   },
   "source": [
    "#### Answer 1(b)\n",
    "\n",
    "Write your answer to 1(b) here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ov4rwwTms3Q"
   },
   "source": [
    "#### Answer 1(c)\n",
    "\n",
    "Write your answer to 1(c) here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVlrfnaims3S"
   },
   "source": [
    "### Question 2 (20 points)\n",
    "\n",
    "\n",
    "\n",
    "In this problem you will search for the best combination of parameters for 'SVC' among  `kernel`, `C`, and `gamma` for classification in the Breast Cancer Data and an accurate measure of the accuracy for the best set of parameters.  \n",
    "\n",
    "Divide out a test set containing 20% of the data using random_state = 0.  Use `MinMaxScaler` if/when necessary for feature normalization. \n",
    "\n",
    "\n",
    "Please search the `kernel` from ('linear', 'rbf'), `C` from (0.1, 0.5, 1, 5, 10), `gamma` from (0.1, 0.5, 1, 5, 10). \n",
    "\n",
    "Please return the best hyper-parameters and the test score associated with the these hyper-parameters.\n",
    "\n",
    "Be careful about the data leakage issues.  Make sure that the returned accuracy is an accurate estimate of the accuracy of the best parameters.  \n",
    "\n",
    "*This function should a return a tuple with four numbers, i.e. `(best_kernel, best_C, best_gamma, test_score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_R4RN4wms3U"
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    import numpy as np\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return best_kernel, best_C, best_gamma, test_score\n",
    "\n",
    "# answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtZuflKLms3h"
   },
   "source": [
    "### Question 3 (20 points)\n",
    "\n",
    "Suppose you have a dataset with some missing values and you know the values are not missing at random and the probability of missing is related to the values themselves. For example, people with higher\n",
    "earnings may be less likely to reveal them. \n",
    "\n",
    "#### (a) (3 points) In this case, what would happen when imputing the missing values with the mean strategy?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWFZ7Orums3j"
   },
   "source": [
    "#### Answer 3(a)\n",
    "\n",
    "Write your anwer here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZ9-gy2Dms3k"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57qAY1nVms3w",
    "outputId": "a090092b-8530-4545-bd6f-20c82214c640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance based on the full data: 0.916\n"
     ]
    }
   ],
   "source": [
    "# Please run this cell first before the question (b)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "d = {}\n",
    "for i in range(len(cancer.feature_names)):\n",
    "    d[cancer.feature_names[i]] = cancer.data[:, i]\n",
    "d['target'] = cancer.target\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "X = df[['mean concave points', 'worst concave points']]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), random_state=0)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('The performance based on the full data: {:.3f}'.format(lr.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "X_train_missing = X_train.copy()\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_train_missing[np.where(u < X_train[:, 0])[0], 0] = np.nan\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_train_missing[np.where(u < X_train[:, 1])[0], 1] = np.nan\n",
    "\n",
    "n_samples = X_test.shape[0]\n",
    "X_test_missing = X_test.copy()\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_test_missing[np.where(u < X_test[:, 0])[0], 0] = np.nan\n",
    "u = rng.uniform(low=0.3, high=1, size=(n_samples,))\n",
    "X_test_missing[np.where(u < X_test[:, 1])[0], 1] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iglMj7Q7ms4J"
   },
   "source": [
    "#### (b) (7 points) \n",
    "\n",
    "Please impute the missing values using `SimpleImputer` with `strategy='mean'`. Then fit a LogisticRegression with default hyper-parameters, and return the imputed data and the test score.\n",
    "\n",
    "\n",
    "*This function should a return a tuple of two arrays and one number: `(X_train_imputed, X_test_imputed, test_score)`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEAXigytms4K"
   },
   "outputs": [],
   "source": [
    "def answer_three_b():\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    \n",
    "    # YOUR CODE HERE.\n",
    "    \n",
    "    return (X_train_imputed, X_test_imputed, test_score)\n",
    "\n",
    "# answer_three_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5EyziwHms4V"
   },
   "source": [
    "#### (c) (5 points) \n",
    "\n",
    "Please impute the missing values using `SimpleImputer` with `strategy='mean'` and `add_indicator=True`. Then fit a LogisticRegression with default hyper-parameters, and return the imputed data and the test score.\n",
    "\n",
    "\n",
    "*This function should a return a tuple of two arrays and one number: `(X_train_imputed, X_test_imputed, test_score)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiPkrnMqms4Z"
   },
   "outputs": [],
   "source": [
    "def answer_three_c():\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # YOUR CODE HERE.\n",
    "\n",
    "    return (X_train_imputed, X_test_imputed, test_score)\n",
    "\n",
    "# answer_three_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlReoDZlms4q"
   },
   "source": [
    "#### (d) (5 points) \n",
    "\n",
    "Why are the additional indicators helpful when the missing values are missing not at random?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poiD02vxms4s"
   },
   "source": [
    "#### Answer 3(d)\n",
    "\n",
    "Write your anwer here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqHhEIztms4u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "si670f20_hw_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
